
service: vautomator-serverless # NOTE: update this with your service name

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
frameworkVersion: ">=1.2.0 <2.0.0"

provider:
  name: aws
  runtime: python3.6
  region: us-west-2
  # To use the bucket specified, we will need permissions
  iamRoleStatements:
   - Effect: "Allow"
     Action:
       - "s3:PutObject"
       - "s3:PutObjectAcl"
     Resource: 
      Fn::Join:
        - ""
        - Fn::GetAtt:
            - S3BucketResults
            - Arn
          - "/*"
   - Effect: "Allow"
     Action:
      - "sqs:SendMessage"
     Resource:
      Fn::GetAtt: [ SQSQueue, Arn ]
   # allow sending to dead-letter queue
   - Sid: LambdaDLQPermissions
     Effect: Allow
     Action:
      - "sqs:SendMessage"
     Resource:
      - Fn::GetAtt:
        - ReceiverDeadLetterQueue
        - Arn
  environment:
    HTTPOBS_URL: 'https://observatory.mozilla.org'
    SQS_URL:
        Ref: SQSQueue

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
#  iamRoleStatements:
#    - Effect: "Allow"
#      Action:
#        - "s3:ListBucket"
#      Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#    - Effect: "Allow"
#      Action:
#        - "s3:PutObject"
#      Resource:
#        Fn::Join:
#          - ""
#          - - "arn:aws:s3:::"
#            - "Ref" : "ServerlessDeploymentBucket"
#            - "/*"

# you can add packaging information here
package:
#  include:
#    - include-me.py
#    - include-me-dir/**
  exclude:
   - .venv/**
   - .git/**
   - __pycache__/**
   - node_modules/**

functions:
  cronPortScan:
    handler: handler.runPortScan
    events:
      # Invoke Lambda function every 15 mins
      - schedule: rate(15 minutes)
  cronObservatoryScan:
    handler: handler.runObsScan
    events:
      # Invoke Lambda function every 5 mins
      - schedule: rate(5 minutes)
      - s3:
        bucket: ${self:custom.cfg.s3BucketName}
        event: s3:ObjectCreated:*
  onDemandObservatoryScan:
    handler: handler.runObsScanOnDemand
    events:
      - http:
          path: ondemand
          method: PUT
          cors: true
  ObservatoryScanQueue:
    handler: handler.runObsScanFromQ
    events:
      - sqs:
          arn:
            Fn::GetAtt: [ SQSQueue, Arn ]
  ingest:
    handler: handler.putInQueue

plugins:
  - serverless-python-requirements

# We will need a bucket to store the results of a scheduled scan
resources:
  Resources:
    S3BucketResults:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.cfg.s3BucketName}
    SQSQueue:
      Type: AWS::SQS::Queue
      Properties:
        QueueName: ${self:custom.cfg.vautomatorQ}
        VisibilityTimeout: 120
        MessageRetentionPeriod: 60
        batchSize: 1
        RedrivePolicy:
          deadLetterTargetArn:
            "Fn::GetAtt":
              - ReceiverDeadLetterQueue
              - Arn
          maxReceiveCount: 1
    ReceiverDeadLetterQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: ${self:custom.cfg.vautomatorDLQ}
        MessageRetentionPeriod: 120 

custom:
  cfg:
    s3BucketName: "vautomator-results"
    vautomatorQ: "vautomator-SQS"
    vautomatorDLQ: "vautomator-DLQ"
  pythonRequirements:
    dockerizePip: non-linux

#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp

#    Define function environment variables here
#    environment:
#      variable2: value2

