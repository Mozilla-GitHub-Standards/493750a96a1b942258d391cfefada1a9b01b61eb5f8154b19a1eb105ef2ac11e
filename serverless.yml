
service: vautomator-serverless
frameworkVersion: ">=1.2.0 <2.0.0"

provider:
  name: aws
  runtime: python3.6
  region: us-west-2
  # To use the bucket specified, we will need permissions
  iamRoleStatements:
   - Effect: "Allow"
     Action:
       - "s3:PutObject"
       - "s3:PutObjectAcl"
     Resource: 
      Fn::Join:
        - ""
        - - Fn::GetAtt:
            - S3BucketResults
            - Arn
          - "/*"
   - Effect: "Allow"
     Action:
      - "sqs:SendMessage"
     Resource:
      Fn::GetAtt: [ SQSQueue, Arn ]
   - Effect: Allow
     Action:
      - "sqs:SendMessage"
     Resource:
      - "Fn::GetAtt":
        - ReceiverDeadLetterQueue
        - Arn
  environment:
    HTTPOBS_API_URL: 'https://http-observatory.security.mozilla.org/api/v1'
    SQS_URL:
      Ref: SQSQueue

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
#  iamRoleStatements:
#    - Effect: "Allow"
#      Action:
#        - "s3:ListBucket"
#      Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#    - Effect: "Allow"
#      Action:
#        - "s3:PutObject"
#      Resource:
#        Fn::Join:
#          - ""
#          - - "arn:aws:s3:::"
#            - "Ref" : "ServerlessDeploymentBucket"
#            - "/*"

# you can add packaging information here
package:
  include:
    - bin/*
  exclude:
    - .venv/**
    - .git/**
    - __pycache__/**
    - node_modules/**

functions:
  onDemandUDPScan:
    handler: handler.runUDP
    timeout: 180
    events:
      - http:
          path: ondemand/udp
          method: POST
          cors: true
  onDemandTCPScan:
    handler: handler.runTCP
    timeout: 180
    events:
      - http:
          path: ondemand/tcp
          method: POST
          cors: true
  cronPortScan:
    handler: handler.runRegularPortScan
    events:
      # Invoke Lambda function once a day
      # We can fine grain it with cron() later
      - schedule: 
          rate: rate(1 day)
          # Not enabling this by default
          enabled: false
  onDemandObservatoryScan:
    handler: handler.putInQueueFromAPIGateway
    events:
      - http:
          path: ondemand
          method: PUT
          cors: true
  cronObservatoryScan:
    handler: handler.runRegularObsScan
functions:
  cronObservatoryScan:
    handler: handler.runScheduledObservatoryScan
    events:
      # Invoke Lambda function every 5 mins
      - schedule: rate(5 minutes)
      - s3:
        bucket: ${self:custom.cfg.s3BucketName}
        event: s3:ObjectCreated:*
  ObservatoryScanQueue:
    handler: handler.runObservatoryScanFromQ
    events:
      - sqs:
          arn:
            Fn::GetAtt: [ SQSQueue, Arn ]
          batchSize: 1
  # Only for manual invocation, not used currently
  # ingest:
  #  handler: handler.putInQueue

plugins:
  - serverless-python-requirements
resources:
  Resources:
    S3BucketResults:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.cfg.s3BucketName}
    ReceiverDeadLetterQueue:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: ${self:custom.cfg.vautomatorDLQ}
        MessageRetentionPeriod: 120
    SQSQueue:
      Type: AWS::SQS::Queue
      Properties:
        QueueName: ${self:custom.cfg.vautomatorQ}
        VisibilityTimeout: 120
        MessageRetentionPeriod: 60
        RedrivePolicy:
          deadLetterTargetArn:
            "Fn::GetAtt":
              - ReceiverDeadLetterQueue
              - Arn
          maxReceiveCount: 1

custom:
  cfg:
    s3BucketName: "vautomator-results"
    vautomatorQ: "vautomator-SQS"
    vautomatorDLQ: "vautomator-DLQ"
  pythonRequirements:
    dockerFile: Dockerfile
    dockerizePip: true

#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp

#    Define function environment variables here
#    environment:
#      variable2: value2

# you can add CloudFormation resource templates here
#resources:
#  Resources:
#    NewResource:
#      Type: AWS::S3::Bucket
#      Properties:
#        BucketName: my-new-bucket
#  Outputs:
#     NewOutput:
#       Description: "Description for the output"
#       Value: "Some output value"
